{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2275763,"sourceType":"datasetVersion","datasetId":1370616}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h3>Data Preprocessing</h3>\n        <p style=\"margin-left: 20px; font-size: 16px;\"> \n        <ul style=\"margin-left: 20px; font-size: 16px;\">\n            <li>Loading original dataset</li>\n            <li>Oversampling the minority classes</li>\n            <li>Resizing images to 128x128</li>\n        </ul>\n        </p>\n","metadata":{}},{"cell_type":"code","source":"#Data Preprocessing\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport random\nfrom imblearn.over_sampling import RandomOverSampler\nimport os\nimport shutil\n\ndef Transform_data():\n    Image_directory  = '/kaggle/input/ham1000-segmentation-and-classification/images/'\n    labels_dir = '/kaggle/input/ham1000-segmentation-and-classification/GroundTruth.csv'\n    classes = {0:'MEL', 1:'NV', 2:'BCC', 3:'AKIEC', 4:'BKL', 5:'DF', 6:'VASC'}\n    classes_num = np.array(list(classes.keys()))\n    \n    labels_df = pd.read_csv(labels_dir)\n    labels_num = np.argmax(labels_df.drop(columns=['image']).values, axis=1)\n    img_names = labels_df['image'].values\n    image_count = len(labels_df['image'].values)\n\n    #Loading Images\n    img_paths = []\n    for img in img_names:\n        img_paths.append(Image_directory + img + \".jpg\")\n    \n    #train, validation, test split\n    data = list( zip(img_paths, labels_num) )\n\n    random.seed(42)\n    random.shuffle(data)\n    \n    val_size = int(len(data) * 0.1)\n    test_size =  int(len(data) * 0.1)\n    \n    val_data = data[:val_size]\n    test_data = data[val_size:(val_size + test_size)]\n    train_data = data[(val_size + test_size):]\n    \n    data = {'train_data': train_data, 'val_data': val_data, 'test_data': test_data}.items()\n    \n    def resize_and_save(input_path, output_path, new_size):\n        original_image = Image.open(input_path)\n        resized_image = original_image.resize(new_size)\n        resized_image.save(output_path)\n            \n    #Oversampling minority classes\n    for chunk in data:\n        chunk_name = chunk[0]\n        chunk_data = chunk[1]\n        oversample = RandomOverSampler(random_state = 3)\n        \n        image_paths, labels_num = map(lambda x: list(x), zip(*chunk_data))\n        img_paths, labels_num  = oversample.fit_resample(np.array(image_paths).reshape(-1, 1), labels_num)\n    \n        print(f\"Processing {chunk_name} Started..\")\n        i = 0\n        for img, label in zip(img_paths.reshape(-1), labels_num):\n            old_img_name = img.split('/')[-1]\n            new_img_name = old_img_name.split('.')[0] + str(i) + '.' + old_img_name.split('.')[1]\n            chunk_class_dir = '/kaggle/working/HAM10000_OverSampled/' + chunk_name + '/' + str(label)\n            if not os.path.exists(chunk_class_dir):\n                os.makedirs(chunk_class_dir)\n\n            output_image_path = os.path.join(chunk_class_dir, new_img_name)\n            new_size = (128, 128)\n            i += 1\n            if (i + 1) % (len(labels_num) // 10) == 0:\n                print()\n                print(\"Progress: \" + str(i) + '/' + str(len(labels_num))+ \" \"+ str(round(i /len(labels_num) * 100))+ \"%\")\n            resize_and_save(img, output_image_path, new_size)\n\n\nTransform_data()\nshutil.make_archive('HAM10000_OverSampled', 'zip', '/kaggle/working/HAM10000_OverSampled')\nprint(\"\\n Data Saved\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-15T08:29:34.537530Z","iopub.execute_input":"2024-02-15T08:29:34.537883Z","iopub.status.idle":"2024-02-15T08:38:06.121565Z","shell.execute_reply.started":"2024-02-15T08:29:34.537856Z","shell.execute_reply":"2024-02-15T08:38:06.120030Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Processing train_data Started..\n\nProgress: 3749/37506 10%\n\nProgress: 7499/37506 20%\n\nProgress: 11249/37506 30%\n\nProgress: 14999/37506 40%\n\nProgress: 18749/37506 50%\n\nProgress: 22499/37506 60%\n\nProgress: 26249/37506 70%\n\nProgress: 29999/37506 80%\n\nProgress: 33749/37506 90%\n\nProgress: 37499/37506 100%\nProcessing val_data Started..\n\nProgress: 471/4725 10%\n\nProgress: 943/4725 20%\n\nProgress: 1415/4725 30%\n\nProgress: 1887/4725 40%\n\nProgress: 2359/4725 50%\n\nProgress: 2831/4725 60%\n\nProgress: 3303/4725 70%\n\nProgress: 3775/4725 80%\n\nProgress: 4247/4725 90%\n\nProgress: 4719/4725 100%\nProcessing test_data Started..\n\nProgress: 469/4704 10%\n\nProgress: 939/4704 20%\n\nProgress: 1409/4704 30%\n\nProgress: 1879/4704 40%\n\nProgress: 2349/4704 50%\n\nProgress: 2819/4704 60%\n\nProgress: 3289/4704 70%\n\nProgress: 3759/4704 80%\n\nProgress: 4229/4704 90%\n\nProgress: 4699/4704 100%\n\n Data Saved\n","output_type":"stream"}]}]}